{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6676d696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import timeit\n",
    "import time\n",
    "import ast\n",
    "import json\n",
    "import joblib\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import model_selection\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import hamming_loss, accuracy_score, f1_score, classification_report\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2f8ac6",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a03c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wk/xh1t9b793w52fjy9qr_0q3pr0000gn/T/ipykernel_72741/1518623246.py:1: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../data/movies_metadata.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(45466, 24)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/movies_metadata.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb46aae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['overview', 'genres']]\n",
    "# df = df.head(5000)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Clean up the genres column\n",
    "df['genres'] = df['genres'].apply(ast.literal_eval) \\\n",
    "                          .apply(lambda x: [i['name'] for i in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d981c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Drama': 20023,\n",
       "         'Comedy': 12806,\n",
       "         'Thriller': 7586,\n",
       "         'Romance': 6673,\n",
       "         'Action': 6565,\n",
       "         'Horror': 4660,\n",
       "         'Crime': 4269,\n",
       "         'Documentary': 3886,\n",
       "         'Adventure': 3470,\n",
       "         'Science Fiction': 3028,\n",
       "         'Family': 2732,\n",
       "         'Mystery': 2451,\n",
       "         'Fantasy': 2290,\n",
       "         'Animation': 1920,\n",
       "         'Foreign': 1599,\n",
       "         'Music': 1588,\n",
       "         'History': 1379,\n",
       "         'War': 1310,\n",
       "         'Western': 1035,\n",
       "         'TV Movie': 751,\n",
       "         'Carousel Productions': 1,\n",
       "         'Vision View Entertainment': 1,\n",
       "         'Telescene Film Group Productions': 1,\n",
       "         'Aniplex': 1,\n",
       "         'GoHands': 1,\n",
       "         'BROSTA TV': 1,\n",
       "         'Mardock Scramble Production Committee': 1,\n",
       "         'Sentai Filmworks': 1,\n",
       "         'Odyssey Media': 1,\n",
       "         'Pulser Productions': 1,\n",
       "         'Rogue State': 1,\n",
       "         'The Cartel': 1})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = Counter([genre for sublist in df['genres'] for genre in sublist])\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "059bbb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rare genres\n",
    "GENRE_FREQ_THRESHOLD = 10\n",
    "popular_genres = [genre for genre, count in counter.items() if count >= GENRE_FREQ_THRESHOLD]\n",
    "\n",
    "df['genres'] = df['genres'].apply(lambda genres: [genre for genre in genres if genre in popular_genres])\n",
    "\n",
    "# Drop rows with no popular genre\n",
    "df['genres'] = df['genres'].apply(lambda genres: genres if len(genres) > 0 else np.nan)\n",
    "df.dropna(subset=['genres'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beb2efc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Action', 'Adventure', 'Animation', 'Comedy', 'Crime',\n",
       "       'Documentary', 'Drama', 'Family', 'Fantasy', 'Foreign', 'History',\n",
       "       'Horror', 'Music', 'Mystery', 'Romance', 'Science Fiction',\n",
       "       'TV Movie', 'Thriller', 'War', 'Western'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding of genres\n",
    "mlb = MultiLabelBinarizer()\n",
    "df_genres = pd.DataFrame(mlb.fit_transform(df.pop('genres')),\n",
    "                          columns=mlb.classes_,\n",
    "                          index=df.index)\n",
    "\n",
    "joblib.dump(mlb, '../models/mlb.joblib')\n",
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a3e68d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(df_genres)\n",
    "df.to_csv('../data/processed_movies_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b84efa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d1d3335",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "290fe692",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed_movies_metadata.csv')\n",
    "\n",
    "X = df['overview']\n",
    "y = df.drop(['overview'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reset indices so that SentenceTransformer encode doesn't complain\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33e33080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, encoder, multilabeler, estimator):\n",
    "    if encoder == 'TfIdf':\n",
    "        encoder_model = TfidfVectorizer().fit(X_train)\n",
    "    elif encoder == 'SentenceTransformer':\n",
    "        encoder_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        encoder_model.transform = encoder_model.encode\n",
    "    \n",
    "    X_encoded = encoder_model.transform(X_train)\n",
    "    classifier_model = multilabeler(estimator=estimator)\n",
    "    classifier_model.fit(X_encoded, y_train)\n",
    "    return (encoder_model, classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c26cf249",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfIdf OneVsRestClassifier LogisticRegression\n",
      "(33859, 65531)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.4589\n",
      "time taken: 14.43s\n",
      "\n",
      "TfIdf OneVsRestClassifier XGBClassifier\n",
      "(33859, 65531)\n",
      "F1 Score: 0.4456\n",
      "time taken: 125.03s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for encoder in ['TfIdf', 'SentenceTransformer']:\n",
    "#     for multilabeler in [OneVsRestClassifier, MultiOutputClassifier]:\n",
    "#         for estimator in [DecisionTreeClassifier, RandomForestClassifier, \n",
    "#                           MultinomialNB, LogisticRegression, xgb.XGBClassifier]:\n",
    "#             if encoder == 'SentenceTransformer' and estimator == MultinomialNB:\n",
    "#                 continue\n",
    "\n",
    "for encoder in ['TfIdf', 'SentenceTransformer']:\n",
    "    multilabeler = OneVsRestClassifier\n",
    "    for estimator in [LogisticRegression, xgb.XGBClassifier]:\n",
    "        start = time.time()\n",
    "        print(encoder, multilabeler.__name__, estimator.__name__)\n",
    "        encoder_model, classifier_model = train_model(X_train, y_train, \n",
    "                                               encoder, multilabeler, estimator())\n",
    "        y_pred = classifier_model.predict(encoder_model.transform(X_test))\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        print(\"F1 Score: %.4f\"%(report['micro avg']['f1-score']))\n",
    "        print(\"Hamming Loss: %.4f\"%(hamming_loss(y_test, y_pred)))\n",
    "        stop = time.time()\n",
    "        print('time taken: %.2fs' %(stop-start))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f606eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(encoder_model, '../models/encoder_model.joblib')\n",
    "joblib.dump(classifier_model, '../models/classifier_model.joblib')\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6bc17aff",
   "metadata": {},
   "source": [
    "tfidf OneVsRestClassifier DecisionTreeClassifier \\t F1 Score: 0.4110 \\t time taken: 16.72s \n",
    "tfidf OneVsRestClassifier RandomForestClassifier \\t F1 Score: 0.3628 \\t time taken: 17.95s \n",
    "tfidf OneVsRestClassifier MultinomialNB \\t F1 Score: 0.3046 \\t time taken: 0.20s \n",
    "tfidf OneVsRestClassifier LogisticRegression \\t F1 Score: 0.3631 \\t time taken: 2.07s \n",
    "tfidf OneVsRestClassifier XGBClassifier \\t F1 Score: 0.4412 \\t time taken: 11.84s \n",
    "tfidf MultiOutputClassifier DecisionTreeClassifier \\t F1 Score: 0.4059 \\t time taken: 16.77s \n",
    "tfidf MultiOutputClassifier RandomForestClassifier \\t F1 Score: 0.3610 \\t time taken: 18.55s \n",
    "tfidf MultiOutputClassifier MultinomialNB \\t F1 Score: 0.3046 \\t time taken: 0.20s \n",
    "tfidf MultiOutputClassifier LogisticRegression \\t F1 Score: 0.3631 \\t time taken: 2.03s \n",
    "tfidf MultiOutputClassifier XGBClassifier \\t F1 Score: 0.4412 \\t time taken: 11.80s \n",
    "\n",
    "SentenceTransformer OneVsRestClassifier DecisionTreeClassifier 0.3636 94.03 \n",
    "SentenceTransformer OneVsRestClassifier RandomForestClassifier 0.3461 142.92 \n",
    "SentenceTransformer OneVsRestClassifier LogisticRegression 0.5248 40.70 \n",
    "SentenceTransformer OneVsRestClassifier XGBClassifier 0.4814 91.20\n",
    "SentenceTransformer MultiOutputClassifier DecisionTreeClassifier 0.3651 96.77\n",
    "SentenceTransformer MultiOutputClassifier RandomForestClassifier 0.3450 142.70 \n",
    "SentenceTransformer MultiOutputClassifier LogisticRegression 0.5248 37.09 \n",
    "SentenceTransformer MultiOutputClassifier XGBClassifier 0.4814 93.67\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf57e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9276d17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for encoder in ['TfIdf', 'SentenceTransformer']:\n",
    "#     for multilabeler in [OneVsRestClassifier, MultiOutputClassifier]:\n",
    "#         for estimator in [DecisionTreeClassifier, RandomForestClassifier, \n",
    "#                           MultinomialNB, LogisticRegression, xgb.XGBClassifier]:\n",
    "#             if encoder == 'SentenceTransformer' and estimator == MultinomialNB:\n",
    "#                 continue\n",
    "#             start = time.time()\n",
    "#             print(encoder, multilabeler.__name__, estimator.__name__)\n",
    "#             encoder_model, genre_clf = train_model(X_train, y_train, \n",
    "#                                                    encoder, multilabeler, estimator())\n",
    "#             y_pred = genre_clf.predict(encoder_model.transform(X_test))\n",
    "\n",
    "#             # Calculate metrics\n",
    "# #             print(\"Hamming Loss: %.4f\"%(hamming_loss(y_test, y_pred)))\n",
    "# #             print(\"Accuracy Score: %.4f\"%(accuracy_score(y_test, y_pred)))\n",
    "#             print(\"F1 Score: %.4f\"%(f1_score(y_test, y_pred, average='micro')))  # average can be: micro, macro, weighted, samples\n",
    "# #             report = classification_report(y_test, y_pred, output_dict=True)\n",
    "# #             print(\"Micro F1 Score: %.4f\"%(report['micro avg']['f1-score']))  # average can be: micro, macro, weighted, samples\n",
    "# #             print(\"Macro F1 Score: %.4f\"%(report['macro avg']['f1-score']))  # average can be: micro, macro, weighted, samples\n",
    "# #             print(\"Weighted F1 Score: %.4f\"%(report['weighted avg']['f1-score']))  # average can be: micro, macro, weighted, samples\n",
    "\n",
    "# #             print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "#             stop = time.time()\n",
    "#             duration = stop - start\n",
    "#             print('time taken: %.2fs' %(duration))\n",
    "#             print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
